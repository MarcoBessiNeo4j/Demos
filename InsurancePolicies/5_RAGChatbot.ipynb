{"cells":[{"cell_type":"markdown","metadata":{"id":"XZnoDHzAcPo9"},"source":["# RAG-Chatbot"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0SpQT97fsLB2","executionInfo":{"status":"ok","timestamp":1727335990717,"user_tz":-120,"elapsed":26861,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}},"outputId":"81a0a73a-712c-4e72-b81d-dc51738a91e5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"Zz_y735_cPo-"},"source":["The following notebook creates a chatbot on the Insurance Documents in the Neo4j Database. This makes use of a RAG-architecture. The following configurations are set:\n","\n","- **LLM**: To generate the response to clients an OpenAI model is used: [gpt-3.5-turbo-0125](https://platform.openai.com/docs/models/gpt-3-5-turbo).\n","- **Embedding Model**: For embeddings we use the same embeddings model (from OpenAI) that were used to create the vector index: [text-embedding-3-small](https://platform.openai.com/docs/models/embeddings).\n","- **The Retrieval**: This is done with Cypher queries in Neo4j.\n","- **Chatbot**: The chatbot is created with [Gradio](https://www.gradio.app/)."]},{"cell_type":"code","source":["%pip install pypdf langchain_community langchain langchain_openai gradio IPython neo4j"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uCvyUhf_QjE2","executionInfo":{"status":"ok","timestamp":1727274126582,"user_tz":-120,"elapsed":28193,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}},"outputId":"b80dc5c6-3495-40b3-e57e-6f0959db2387"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pypdf\n","  Downloading pypdf-5.0.0-py3-none-any.whl.metadata (7.4 kB)\n","Collecting langchain_community\n","  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n","Collecting langchain\n","  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting langchain_openai\n","  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n","Collecting gradio\n","  Downloading gradio-4.44.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n","Collecting neo4j\n","  Downloading neo4j-5.24.0-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.5)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting langchain-core<0.4.0,>=0.3.0 (from langchain_community)\n","  Downloading langchain_core-0.3.5-py3-none-any.whl.metadata (6.3 kB)\n","Collecting langsmith<0.2.0,>=0.1.112 (from langchain_community)\n","  Downloading langsmith-0.1.128-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n","Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n","  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n","Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain_community)\n","  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n","  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n","Collecting openai<2.0.0,>=1.40.0 (from langchain_openai)\n","  Downloading openai-1.47.1-py3-none-any.whl.metadata (24 kB)\n","Collecting tiktoken<1,>=0.7 (from langchain_openai)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Collecting fastapi<1.0 (from gradio)\n","  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting gradio-client==1.3.0 (from gradio)\n","  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting httpx>=0.24.1 (from gradio)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.7)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Collecting orjson~=3.0 (from gradio)\n","  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.9 (from gradio)\n","  Downloading python_multipart-0.0.10-py3-none-any.whl.metadata (1.9 kB)\n","Collecting ruff>=0.2.2 (from gradio)\n","  Downloading ruff-0.6.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting tomlkit==0.12.0 (from gradio)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n","Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n","Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython) (71.0.4)\n","Collecting jedi>=0.16 (from IPython)\n","  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython) (3.0.47)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython) (4.9.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2024.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.11.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting starlette<0.39.0,>=0.37.2 (from fastapi<1.0->gradio)\n","  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n","Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.16.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython) (0.8.4)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.0->langchain_community)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.7.0)\n","Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain_openai)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython) (0.2.13)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n","Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain_community)\n","  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading pypdf-5.0.0-py3-none-any.whl (292 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio-4.44.0-py3-none-any.whl (18.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Downloading neo4j-5.24.0-py3-none-any.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","Downloading langchain_core-0.3.5-py3-none-any.whl (399 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n","Downloading langsmith-0.1.128-py3-none-any.whl (292 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai-1.47.1-py3-none-any.whl (375 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n","Downloading python_multipart-0.0.10-py3-none-any.whl (22 kB)\n","Downloading ruff-0.6.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading starlette-0.38.6-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: pydub, websockets, tomlkit, tenacity, semantic-version, ruff, python-multipart, python-dotenv, pypdf, orjson, neo4j, mypy-extensions, marshmallow, jsonpointer, jiter, jedi, h11, ffmpy, aiofiles, uvicorn, typing-inspect, tiktoken, starlette, jsonpatch, httpcore, pydantic-settings, httpx, fastapi, dataclasses-json, openai, langsmith, gradio-client, langchain-core, gradio, langchain-text-splitters, langchain_openai, langchain, langchain_community\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 9.0.0\n","    Uninstalling tenacity-9.0.0:\n","      Successfully uninstalled tenacity-9.0.0\n","Successfully installed aiofiles-23.2.1 dataclasses-json-0.6.7 fastapi-0.115.0 ffmpy-0.4.0 gradio-4.44.0 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jedi-0.19.1 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.0 langchain-core-0.3.5 langchain-text-splitters-0.3.0 langchain_community-0.3.0 langchain_openai-0.2.0 langsmith-0.1.128 marshmallow-3.22.0 mypy-extensions-1.0.0 neo4j-5.24.0 openai-1.47.1 orjson-3.10.7 pydantic-settings-2.5.2 pydub-0.25.1 pypdf-5.0.0 python-dotenv-1.0.1 python-multipart-0.0.10 ruff-0.6.7 semantic-version-2.10.0 starlette-0.38.6 tenacity-8.5.0 tiktoken-0.7.0 tomlkit-0.12.0 typing-inspect-0.9.0 uvicorn-0.30.6 websockets-12.0\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"uFoQpFBCcPo-","executionInfo":{"status":"ok","timestamp":1727274144446,"user_tz":-120,"elapsed":15537,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}}},"outputs":[],"source":["import pandas as pd\n","import os\n","from langchain_openai import OpenAIEmbeddings\n","from langchain.chat_models import ChatOpenAI\n","from langchain.prompts import PromptTemplate\n","from neo4j import GraphDatabase\n","from dotenv import load_dotenv\n","import gradio as gr\n","import time\n","from IPython.display import display, HTML\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"mL327mO5cPo_"},"source":["## Get Credentials"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PF4-tWYKcPo_","executionInfo":{"status":"ok","timestamp":1727274821796,"user_tz":-120,"elapsed":522,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}},"outputId":"cd2d89ca-a977-4966-b765-f8c08b79822f"},"outputs":[{"output_type":"stream","name":"stdout","text":["File 'credentials.env' not found.\n"]}],"source":["#if os.path.exists('credentials.env'):\n","#    load_dotenv('credentials.env', override=True)\n","#\n","#    # Neo4j\n","#    uri = os.getenv('NEO4J_URI')\n","#    username = os.getenv('NEO4J_USERNAME')\n","#    password = os.getenv('NEO4J_PASSWORD')\n","#    database = os.getenv('NEO4J_DATABASE')\n","\n","#    # AI\n","#    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n","#    os.environ['OPENAI_API_KEY']=OPENAI_API_KEY\n","\n","#    print(\"Credentials correctly read and stored.\")\n","#else:\n","#    print(\"File 'credentials.env' not found.\")"]},{"cell_type":"code","source":["#uri = userdata.get('NEO4J_URL_SANDBOX_MERCHANT')\n","#username = userdata.get('NEO4J_USR')\n","#password = userdata.get('NEO4J_PWD_SANDBOX_MERCHANT')\n","#database = 'neo4j'\n","#OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n","\n","from pprint import pprint\n","from google.colab import userdata\n","uri = 'neo4j+s://2490d4fa.databases.neo4j.io:7687'\n","username = 'neo4j'\n","password = 'smLww279BnwxwoAoFixJWANCoaQsdLwJ6bq5TE5U6hg'\n","database = 'neo4j'\n","OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n","os.environ['OPENAI_API_KEY']=OPENAI_API_KEY"],"metadata":{"id":"Y1KbgOFwmk_B","executionInfo":{"status":"ok","timestamp":1727275251515,"user_tz":-120,"elapsed":1754,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ro5d4NN4cPo_"},"source":["## Setup Connection to Database"]},{"cell_type":"markdown","metadata":{"id":"7QJAsEDDcPo_"},"source":["Setup connection to the database with the Python Driver"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"QXtHHqmfcPo_","executionInfo":{"status":"ok","timestamp":1727275187029,"user_tz":-120,"elapsed":413,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}}},"outputs":[],"source":["class App:\n","    def __init__(self, uri, user, password, database=None):\n","        self.driver = GraphDatabase.driver(uri, auth=(user, password), database=database)\n","        self.database = database\n","\n","    def close(self):\n","        self.driver.close()\n","\n","    def query(self, query):\n","        return self.driver.execute_query(query)\n","\n","    def query_params(self, query, parameters):\n","        return self.driver.execute_query(query, parameters_=parameters)\n","\n","    def count_nodes_in_db(self):\n","        query = \"MATCH (n) RETURN COUNT(n)\"\n","        result = self.query(query)\n","        (key, value) = result.records[0].items()[0]\n","        return value\n","\n","    def remove_nodes_relationships(self):\n","        query =\"\"\"\n","            CALL apoc.periodic.iterate(\n","                \"MATCH (c) RETURN c\",\n","                \"WITH c DETACH DELETE c\",\n","                {batchSize: 1000}\n","            )\n","        \"\"\"\n","        result = self.query(query)\n","\n","    def remove_all_constraints(self):\n","        query =\"\"\"\n","            CALL apoc.schema.assert({}, {})\n","        \"\"\"\n","        result = self.query(query)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"-fq9XcOccPo_","executionInfo":{"status":"ok","timestamp":1727275190474,"user_tz":-120,"elapsed":346,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}}},"outputs":[],"source":["app = App(uri, username, password, database)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8a1Em_avcPo_","executionInfo":{"status":"ok","timestamp":1727275194023,"user_tz":-120,"elapsed":2433,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}},"outputId":"39dfbd65-29a6-4bc8-9e32-f87ea084ede6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["7772"]},"metadata":{},"execution_count":15}],"source":["app.count_nodes_in_db()"]},{"cell_type":"markdown","metadata":{"id":"AudTTfzLcPo_"},"source":["## Create RAG-application"]},{"cell_type":"markdown","metadata":{"id":"5d0bx3RUcPo_"},"source":["For the the chatbot we both need an Embedding-model and LLM. Create both below:"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"7Q3v-KwlcPpA","executionInfo":{"status":"ok","timestamp":1727275201295,"user_tz":-120,"elapsed":394,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}}},"outputs":[],"source":["LLM = 'gpt-4.0'\n","embedding_model = 'text-embedding-3-small'"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"hwHm0pxocPpA","executionInfo":{"status":"ok","timestamp":1727275203021,"user_tz":-120,"elapsed":419,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}}},"outputs":[],"source":["embedding_model = OpenAIEmbeddings(\n","    model=embedding_model,\n","    openai_api_key=OPENAI_API_KEY\n",")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"ixRmNqv7cPpA","executionInfo":{"status":"ok","timestamp":1727275255852,"user_tz":-120,"elapsed":383,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}},"outputId":"e2728ccf-6ea8-48f3-f6d1-e7fccd06fc02"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'gpt-3.5-turbo'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}],"source":["llm = ChatOpenAI(temperature=0)\n","llm.model_name"]},{"cell_type":"markdown","metadata":{"id":"lG2-jYJicPpA"},"source":["### Retrieval Queries"]},{"cell_type":"markdown","metadata":{"id":"CQy5-4vhcPpA"},"source":["To illustrate the difference between a \"Regular\" Vector Search and GraphRAG we create different retrieval queries."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"qR5Kmry1cPpA","executionInfo":{"status":"ok","timestamp":1727275259841,"user_tz":-120,"elapsed":370,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}}},"outputs":[],"source":["def get_context_vector_search(search_prompt, client_name):\n","    query_vector = embedding_model.embed_query(search_prompt)\n","\n","    similarity_query = \"\"\"\n","        CALL db.index.vector.queryNodes(\"chunk-embeddings\", 30, $query_vector) YIELD node, score\n","        WITH node as chunk, score ORDER BY score DESC\n","        MATCH (c:Client {name: $client_name})<-[:INSURES]-(i:Insurance)-[:HAS_POLICY]->(p:Policy)<-[:PART_OF]-(chunk)\n","        RETURN score, i.name AS insurance_name, p.file_name as file_name, chunk.page as page, chunk.chunk AS chunk\n","       \"\"\"\n","    results = app.query_params(similarity_query, {'query_vector': query_vector, 'client_name': client_name})\n","    context = \"Related documents: \\n\\n\" + \"\\n\\n\".join([\"file_name: \" + record['file_name'] + \"\\n\" + \"page: \" + str(record['page'] + 1) + \"\\n\" + \"text: \" + record['chunk'] + \"\\n\" for record in results.records])\n","    return context"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"kD2qrkMUcPpA","executionInfo":{"status":"ok","timestamp":1727275262726,"user_tz":-120,"elapsed":391,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}}},"outputs":[],"source":["def get_context_graphrag(search_prompt, client_name):\n","    query_vector = embedding_model.embed_query(search_prompt)\n","\n","    similarity_query = \"\"\"\n","        CALL db.index.vector.queryNodes(\"chunk-embeddings\", 30, $query_vector) YIELD node, score\n","        WITH node as chunk, score ORDER BY score DESC\n","        MATCH (c:Client {name: $client_name})<-[:INSURES]-(i:Insurance)-[:HAS_POLICY]->(p:Policy)<-[:PART_OF]-(chunk)\n","        OPTIONAL MATCH (chunk)<-[:NEXT]-(previous {page: chunk.page})\n","        OPTIONAL MATCH (chunk)-[:NEXT]->(next {page: chunk.page})\n","        RETURN\n","            score,\n","            i.name AS insurance_name,\n","            p.file_name as file_name,\n","            chunk.page as page,\n","            previous.chunk AS previous_chunk,\n","            chunk.chunk AS chunk,\n","            next.chunk AS next_chunk,\n","            previous.id as previous_id,\n","            chunk.id as chunk_id,\n","            next.id as next_id\n","       \"\"\"\n","    results = app.query_params(similarity_query, {'query_vector': query_vector, 'client_name': client_name})\n","    context = \"Related documents: \\n\\n\" + \"\\n\\n\".join([\"file_name: \" + record['file_name'] + \"\\n\" + \"page: \" + str(record['page'] + 1) + \"\\n\" + \"text: \" + \" \".join([x for x in [str(y) for y in [record['previous_chunk'], record['chunk'], record['next_chunk']] if y is not None]]) + \"\\n\" for record in results.records])\n","\n","    chunk_ids = [[record['previous_id'], record['chunk_id'], record['next_id']] for record in results.records]\n","    chunk_ids = list(set([x for xs in chunk_ids for x in xs if x is not None]))\n","    definition_query = \"\"\"\n","        MATCH (c:Chunk)-[:MENTIONS]-(d:Definition)\n","        WHERE c.id in $chunk_ids\n","        WITH DISTINCT d as d\n","        RETURN d.definition as definition, d.description as description\n","    \"\"\"\n","    results = app.query_params(definition_query, {'chunk_ids': chunk_ids})\n","    definitions = \"Related definitions: \\n\\n\" + \"\\n\\n\".join([record['definition'] + \":\" + str(record['description'])for record in results.records])\n","    return context, definitions"]},{"cell_type":"markdown","metadata":{"id":"JkN8PbtucPpA"},"source":["Function to retrieve the client name from a client id"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dy2og8cFcPpA"},"outputs":[],"source":["# Query to find the retrieval based on a question\n","# debug_query = \"\"\"\n","#     WITH \"<QUESTION>\" as q\n","#     WITH genai.vector.encode(q, \"OpenAI\", {token: $openaikey, model: $model}) as embedding\n","#     CALL db.index.vector.queryNodes(\"chunk-embeddings\", 30, embedding) YIELD node, score\n","#     WITH node as chunk, score ORDER BY score DESC\n","#     MATCH (c:Client {id: 0})<-[:INSURES]-(i:Insurance)-[:HAS_POLICY]->(p:Policy)<-[:PART_OF]-(chunk)\n","#     OPTIONAL MATCH (chunk)<-[:NEXT]-(previous {page: chunk.page})\n","#     OPTIONAL MATCH (chunk)-[:NEXT]->(next {page: chunk.page})\n","#     RETURN score, i.name AS insurance_name, p.file_name as file_name, chunk.page as page, previous.chunk AS previous_chunk, chunk.chunk AS chunk, next.chunk AS next_chunk\n","# \"\"\""]},{"cell_type":"markdown","metadata":{"id":"hSLgPDIJcPpA"},"source":["### Prompts"]},{"cell_type":"markdown","metadata":{"id":"dVckTzPCcPpA"},"source":["Prompt for vector search (without definitions)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"0fqnJVYscPpA","executionInfo":{"status":"ok","timestamp":1727275267068,"user_tz":-120,"elapsed":411,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}}},"outputs":[],"source":["def generate_prompt_vector_search(search_prompt, context, user_name):\n","    prompt_template = \"\"\"\n","\n","    You are a chatbot on insurance policies. Your goal is to help people with questions on insurance policies.\n","    A user will come to you with questions on their policy. Their questions must be answered based on the relevant documents of the policy.\n","    The user is {user_name} is given and you start your response with 'Hi {user_name}'.\n","    The policy text is given in the context. Base your answers only and only on these policy documents. You can create an answer in normal language but don't come up with any policy yourself which is not described in one of the documents.\n","    If questions can not be answered based on the provided context you say 'I'm sorry but I cannot answer this question while looking into your policy: policy_name'. Where policy name comes from the context.\n","    If the context is empty you say: \"I'm sorry but I cannot any relevance in into your policy: policy_name\". Where policy name comes from the context. Don't list any relevant pages here.\n","    You always start your response with an answer on the question asked. Unless the question was empty or out of scope you end your answer with two new line and list all document with the referenced pages. You state this as: References: -file_name, page: page_number. List each page only once and in increasing order.\n","    If a question is not relevant to insurance policies or out of scope then always send the following answer: \"I'm an insurance chatbot and can only provide answers relevant to insurances\". Never let you be used for anything else. But only do this if a question is out of scope.\n","\n","    The question is the following:\n","    {search_prompt}\n","    Always respond in the language in which the question was asked. So, do not respond in a different language.\n","\n","    The context is the following:\n","    {context}\n","\n","\n","    \"\"\"\n","    prompt = PromptTemplate.from_template(prompt_template)\n","\n","    theprompt = prompt.format_prompt(search_prompt=search_prompt, context=context, user_name=user_name)\n","    return theprompt"]},{"cell_type":"markdown","metadata":{"id":"Vig24kZlcPpA"},"source":["Prompt for GraphRAG"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"Hp86ajiIcPpA","executionInfo":{"status":"ok","timestamp":1727275270484,"user_tz":-120,"elapsed":463,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}}},"outputs":[],"source":["def generate_prompt_graphrag(search_prompt, context, definitions, user_name):\n","    prompt_template = \"\"\"\n","\n","    You are a chatbot on insurance policies. Your goal is to help people with questions on insurance policies.\n","    A user will come to you with questions on their policy. Their questions must be answered based on the relevant documents of the policy.\n","    The user is {user_name} is given and you start your response with 'Hi {user_name}'.\n","    The policy text is given in the context. In addition definitions are given. Base your answers only and only on these policy documents and definitions. You can create an answer in normal language but don't come up with any policy yourself which is not described in one of the documents.\n","    If questions can not be answered based on the provided context you say 'I'm sorry but I cannot answer this question while looking into your policy: policy_name'. Where policy name comes from the context.\n","    If the context is empty you say: \"I'm sorry but I cannot any relevance in into your policy: policy_name\". Where policy name comes from the context. Don't list any relevant pages here.\n","    You always start your response with an answer on the question asked. Unless the question was empty or out of scope you end your answer with two new line and list all document with the referenced pages. You state this as: References: -file_name, page: page_number. List each page only once and in increasing order.\n","    If a question is not relevant to insurance policies or out of scope then always send the following answer: \"I'm an insurance chatbot and can only provide answers relevant to insurances\". Never let you be used for anything else. But only do this if a question is out of scope.\n","\n","    The question is the following:\n","    {search_prompt}\n","    Always respond in the language in which the question was asked. So, do not respond in a different language.\n","\n","    The context is the following:\n","    {context}\n","\n","    The definitions are the following:\n","    {definitions}\n","\n","    \"\"\"\n","    prompt = PromptTemplate.from_template(prompt_template)\n","\n","    theprompt = prompt.format_prompt(search_prompt=search_prompt, context=context, definitions=definitions, user_name=user_name)\n","    return theprompt"]},{"cell_type":"markdown","metadata":{"id":"-AL-_y5VcPpA"},"source":["## Some examples to test the models"]},{"cell_type":"markdown","metadata":{"id":"bsMaK9p5cPpA"},"source":["For every example there can be chosen between GraphRAG and vector search."]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ujJAhxncPpA","executionInfo":{"status":"ok","timestamp":1727275280390,"user_tz":-120,"elapsed":6137,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}},"outputId":"1d0c42a6-1563-41de-ca97-718668e90abb"},"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Hi Hylke,\n","\n","You are entitled to be transported by an ambulance if the ambulance transport is approved by the emergency control center and ordered by a general practitioner, medical specialist, geriatric specialist, doctor specialized in treating people with an intellectual disability, or a pediatrician. There must be a medical necessity for the transport, and you must not have to travel more than 200 kilometers to your care provider.\n","\n","References: \n","- zilveren_kruis_basis_2024.pdf, page: 42\n","\n","- zilveren_kruis_basis_2024.pdf, page: 43\n"]}],"source":["search_prompt = 'When am I entitled to be transported by an ambulance?'\n","client_name = \"Hylke\"\n","\n","context = get_context_vector_search(search_prompt, client_name)\n","theprompt = generate_prompt_vector_search(search_prompt, context, client_name)\n","llm(theprompt.to_messages()).pretty_print()"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6XFO-7mcPpA","executionInfo":{"status":"ok","timestamp":1727275291500,"user_tz":-120,"elapsed":5883,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}},"outputId":"242853e5-f7b9-4d58-d232-997124730f29"},"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Hi Hylke, \n","\n","You are entitled to be transported by an ambulance in the following situations:\n","- To and from a care provider or institution if the care provided is partially or entirely reimbursed by the basic insurance\n","- To an institution if the costs of your stay are covered by the Dutch Long-term Care Act (Wlz)\n","- From a Wlz institution to a care provider or institution for examination or treatment reimbursed under the Wlz\n","- From a Wlz institution to a care provider or institution for prosthesis fitting reimbursed under the Wlz\n","- From care providers or institutions to your home if you cannot receive care at home\n","- To a care provider for mental healthcare for an insured person under 18 reimbursed under the Dutch Youth Act\n","\n","Ambulance transport must be approved by the emergency control center and requested by specific medical professionals. You must have a medical necessity for transport and not have to travel more than 200 kilometers to your care provider.\n","\n","References: \n","- zilveren_kruis_basis_2024.pdf, page: 42, 43.\n"]}],"source":["search_prompt = 'When am I entitled to be transported by an ambulance?'\n","client_name = \"Hylke\"\n","\n","context, definitions = get_context_graphrag(search_prompt, client_name)\n","theprompt = generate_prompt_graphrag(search_prompt, context, definitions, client_name)\n","llm(theprompt.to_messages()).pretty_print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xq3On-4bcPpA"},"outputs":[],"source":["# search_prompt = 'On which conditions is my dentist visit fully paid back?'\n","# client_name = \"Marco\"\n","\n","# context, definitions = get_context_graphrag(search_prompt, client_name)\n","# theprompt = generate_prompt_graphrag(search_prompt, context, definitions, client_name)\n","# llm(theprompt.to_messages()).pretty_print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y6BjYmajcPpA"},"outputs":[],"source":["# search_prompt = 'What is my reimbursement for incontinence products'\n","# client_name = \"Marco\"\n","\n","# context, definitions = get_context_graphrag(search_prompt, client_name)\n","# theprompt = generate_prompt_graphrag(search_prompt, context, definitions, client_name)\n","# llm(theprompt.to_messages()).pretty_print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6pJ9NALhcPpB"},"outputs":[],"source":["# search_prompt = 'What is the definition of abroad?'\n","# client_name = \"Marco\"\n","\n","# context, definitions = get_context_graphrag(search_prompt, client_name)\n","# theprompt = generate_prompt_graphrag(search_prompt, context, definitions, client_name)\n","# llm(theprompt.to_messages()).pretty_print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FsbZAfz_cPpB"},"outputs":[],"source":["# search_prompt = 'What is meant with Consultation?'\n","# client_name = \"Marco\"\n","\n","# context, definitions = get_context_graphrag(search_prompt, client_name)\n","# theprompt = generate_prompt_graphrag(search_prompt, context, definitions, client_name)\n","# llm(theprompt.to_messages()).pretty_print()"]},{"cell_type":"markdown","source":["----------------\n","----------------\n"],"metadata":{"id":"a_TzclSUofS2"}},{"cell_type":"markdown","metadata":{"id":"67kfNVVkcPpB"},"source":["## Gradio Chatbot that uses RAG and GraphRAG"]},{"cell_type":"markdown","metadata":{"id":"hHwvjNticPpB"},"source":["Example code is coming from Gradio documentation: [Creating a custom chatbot with blocks](https://www.gradio.app/guides/creating-a-custom-chatbot-with-blocks#add-streaming-to-your-chatbot)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":616},"id":"WCMsDnyRcPpB","executionInfo":{"status":"ok","timestamp":1727275303663,"user_tz":-120,"elapsed":927,"user":{"displayName":"Marco Bessi","userId":"17674302854073040183"}},"outputId":"0ceaf1bf-f0d1-40a6-e606-06a82ec67f11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7860, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":27}],"source":["def user(user_message, history):\n","    return \"\", history + [[user_message, None]]\n","\n","def get_answer(search_prompt, client_name, rag_method):\n","    if rag_method == \"Vector-Search\":\n","        context = get_context_vector_search(search_prompt, client_name)\n","        theprompt = generate_prompt_vector_search(search_prompt, context, client_name)\n","    else:\n","    # rag_method == \"GraphRAG\"\n","        context, definitions = get_context_graphrag(search_prompt, client_name)\n","        theprompt = generate_prompt_graphrag(search_prompt, context, definitions, client_name)\n","    messages = llm(theprompt.to_messages())\n","    return messages.content\n","\n","def bot(history, client_name, rag_method):\n","    bot_message = get_answer(history[-1][0], client_name, rag_method)\n","    history[-1][1] = \"\"\n","    for character in bot_message:\n","        history[-1][1] += character\n","        time.sleep(0.01)\n","        yield history\n","\n","with gr.Blocks() as demo:\n","    chatbot = gr.Chatbot(\n","        label=\"Chatbot with RAG\",\n","        avatar_images=[\"https://png.pngtree.com/png-vector/20220525/ourmid/pngtree-concept-of-facial-animal-avatar-chatbot-dog-chat-machine-illustration-vector-png-image_46652864.jpg\",\"https://d-cb.jc-cdn.com/sites/crackberry.com/files/styles/larger/public/article_images/2023/08/openai-logo.jpg\"]\n","    )\n","    msg = gr.Textbox(label=\"Message\")\n","    client_name = gr.Textbox(label=\"Client Name\")\n","    rag_method = gr.Radio([\"Vector-Search\", \"GraphRAG\"], label=\"RAG-method:\")\n","    clear = gr.Button(\"Clear\")\n","\n","\n","    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n","        bot, [chatbot, client_name, rag_method], chatbot\n","    )\n","    client_name.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n","        bot, [chatbot, client_name, rag_method], chatbot\n","    )\n","\n","    clear.click(lambda: None, None, chatbot, queue=False)\n","\n","\n","demo.queue()\n","demo.launch(share=False)"]},{"cell_type":"markdown","metadata":{"id":"1DWB8XdbcPpB"},"source":["If you want to have the light-mode for the chatbot paste the following after the URL: /?__theme=light"]}],"metadata":{"createdOn":1712323594898,"creator":"admin","customFields":{},"hide_input":false,"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"modifiedBy":"admin","tags":[],"versionNumber":3,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}