{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Named Entity Recognition with LLMs**"
      ],
      "metadata": {
        "id": "vlIt1bFZ0-lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install retry\n",
        "!pip install neo4j openai graphdatascience"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya12GbHi4Nc5",
        "outputId": "6ef7862b-7fbc-4732-b44f-67a25e254771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: retry in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.10/dist-packages (from retry) (4.4.2)\n",
            "Requirement already satisfied: py<2.0.0,>=1.4.26 in /usr/local/lib/python3.10/dist-packages (from retry) (1.11.0)\n",
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.10/dist-packages (5.18.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.14.3)\n",
            "Collecting graphdatascience\n",
            "  Downloading graphdatascience-1.9-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2023.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Collecting multimethod<2.0,>=1.0 (from graphdatascience)\n",
            "  Downloading multimethod-1.11.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from graphdatascience) (1.5.3)\n",
            "Requirement already satisfied: pyarrow<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from graphdatascience) (14.0.2)\n",
            "Collecting textdistance<5.0,>=4.0 (from graphdatascience)\n",
            "  Downloading textdistance-4.6.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from graphdatascience) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->graphdatascience) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->graphdatascience) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->graphdatascience) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->graphdatascience) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<3.0,>=1.0->graphdatascience) (1.16.0)\n",
            "Installing collected packages: textdistance, multimethod, graphdatascience\n",
            "Successfully installed graphdatascience-1.9 multimethod-1.11.2 textdistance-4.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from retry import retry\n",
        "import re\n",
        "from string import Template\n",
        "import json\n",
        "import ast\n",
        "import time\n",
        "import pandas as pd\n",
        "from graphdatascience import GraphDataScience\n",
        "import glob\n",
        "from timeit import default_timer as timer\n",
        "# from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "vGc9zkwC4HD3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "7d998ee2-38a4-4d5e-dbde-d28abc206b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'graphdatascience'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2d0d09291aa1>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgraphdatascience\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphDataScience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtimeit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefault_timer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphdatascience'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "  clean = \"\\n\".join([row for row in text.split(\"\\n\")])\n",
        "  clean = re.sub(r'\\(fig[^)]*\\)', '', clean, flags=re.IGNORECASE)\n",
        "  return clean"
      ],
      "metadata": {
        "id": "Ep6vlQdqYV0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_txt = \"\"\"The patient was a 34-yr-old man who presented with complaints of fever and a chronic cough.\n",
        "He was a smoker and had a history of pulmonary tuberculosis that had been treated and cured.\n",
        "A computed tomographic (CT) scan revealed multiple tiny nodules in both lungs.\n",
        "A thoracoscopic lung biopsy was taken from the right upper lobe.\n",
        "The microscopic examination revealed a typical LCH.\n",
        "The tumor cells had vesicular and grooved nuclei, and they formed small aggregations around the bronchioles (Fig.1).\n",
        "The tumor cells were strongly positive for S-100 protein, vimentin, CD68 and CD1a.\n",
        "There were infiltrations of lymphocytes and eosinophils around the tumor cells.\n",
        "With performing additional radiologic examinations, no other organs were thought to be involved.\n",
        "He quit smoking, but he received no other specific treatment.\n",
        "He was well for the following one year.\n",
        "After this, a follow-up CT scan was performed and it showed a 4 cm-sized mass in the left lower lobe, in addition to the multiple tiny nodules in both lungs (Fig.2).\n",
        "A needle biopsy specimen revealed the possibility of a sarcoma; therefore, a lobectomy was performed.\n",
        "Grossly, a 4 cm-sized poorly-circumscribed lobulated gray-white mass was found (Fig.3), and there were a few small satellite nodules around the main mass.\n",
        "Microscopically, the tumor cells were aggregated in large sheets and they showed an infiltrative growth.\n",
        "The cytologic features of some of the tumor cells were similar to those seen in a typical LCH.\n",
        "However, many tumor cells showed overtly malignant cytologic features such as pleomorphic/hyperchromatic nuclei and prominent nucleoli (Fig.4), and multinucleated tumor giant cells were also found.\n",
        "There were numerous mitotic figures ranging from 30 to 60 per 10 high power fields, and some of them were abnormal.\n",
        "A few foci of typical LCH remained around the main tumor mass.\n",
        "Immunohistochemically, the tumor cells were strongly positive for S-100 protein (Fig.5) and vimentin; they were also positive for CD68 (Dako N1577, Clone KPI), and focally positive for CD1a (Fig.6), and they were negative for cytokeratin, epithelial membrane antigen, CD3, CD20 and HMB45.\n",
        "The ultrastructural analysis failed to demonstrate any Birbeck granules in the cytoplasm of the tumor cells.\n",
        "Now, at five months after lobectomy, the patient is doing well with no significant change in the radiologic findings.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "KePmq5aoYVxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT-4 Prompt to complete\n",
        "client = OpenAI(api_key=openai.api_key)\n",
        "# @retry(tries=2, delay=5)\n",
        "def process_gpt(system,\n",
        "                prompt):\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        max_tokens=4000,\n",
        "        # Try to be as deterministic as possible\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ]\n",
        "    )\n",
        "    nlp_results = completion.choices[0].message.content\n",
        "    return nlp_results"
      ],
      "metadata": {
        "id": "xwQGFaAn07Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UJk9xQlJ07MN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90379cd1"
      },
      "outputs": [],
      "source": [
        "prompt1=\"\"\"From the Case sheet for a patient below, extract the following Entities & relationships described in the mentioned format\n",
        "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
        "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
        "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. Document must be summarized and stored inside Case entity under `summary` property. You will have to generate as many entities as needed as per the types below:\n",
        "    Entity Types:\n",
        "    label:'Case',id:string,summary:string //Case\n",
        "    label:'Person',id:string,age:string,location:string,gender:string //Patient mentioned in the case\n",
        "    label:'Symptom',id:string,description:string //Symptom Entity; `id` property is the name of the symptom, in lowercase & camel-case & should always start with an alphabet\n",
        "    label:'Disease',id:string,name:string //Disease diagnosed now or previously as per the Case sheet; `id` property is the name of the disease, in lowercase & camel-case & should always start with an alphabet\n",
        "    label:'BodySystem',id:string,name:string //Body Part affected. Eg: Chest, Lungs; id property is the name of the part, in lowercase & camel-case & should always start with an alphabet\n",
        "    label:'Diagnosis',id:string,name:string,description:string,when:string //Diagnostic procedure conducted; `id` property is the summary of the Diagnosis, in lowercase & camel-case & should always start with an alphabet\n",
        "    label:'Biological',id:string,name:string,description:string //Results identified from Diagnosis; `id` property is the summary of the Biological, in lowercase & camel-case & should always start with an alphabet\n",
        "\n",
        "3. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
        "    Relationship types:\n",
        "    case|FOR|person\n",
        "    person|HAS_SYMPTOM{when:string,frequency:string,span:string}|symptom //the properties inside HAS_SYMPTOM gets populated from the Case sheet\n",
        "    person|HAS_DISEASE{when:string}|disease //the properties inside HAS_DISEASE gets populated from the Case sheet\n",
        "    symptom|SEEN_ON|chest\n",
        "    disease|AFFECTS|heart\n",
        "    person|HAS_DIAGNOSIS|diagnosis\n",
        "    diagnosis|SHOWED|biological\n",
        "\n",
        "The output should look like :\n",
        "{\n",
        "    \"entities\": [{\"label\":\"Case\",\"id\":string,\"summary\":string}],\n",
        "    \"relationships\": [\"disease|AFFECTS|heart\"]\n",
        "}\n",
        "\n",
        "Case Sheet:\n",
        "$ctext\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A2Wo5Vqf07KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98cbafb5",
        "outputId": "d065bbec-9f0f-452c-e359-c3338bf35291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 247 ms, sys: 39.2 ms, total: 287 ms\n",
            "Wall time: 49.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "def run_completion(prompt, results, ctext):\n",
        "    try:\n",
        "      system = \"You are a helpful Medical Case Sheet expert who extracts relevant information and store them on a Neo4j Knowledge Graph\"\n",
        "      pr = Template(prompt).substitute(ctext=ctext)\n",
        "      res = process_gpt(system, pr)\n",
        "      results.append(json.loads(res.replace(\"\\'\", \"'\")))\n",
        "      return results\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "prompts = [prompt1]\n",
        "results = []\n",
        "for p in prompts:\n",
        "  results = run_completion(p, results, clean_text(article_txt))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogK6_qAS07Hi",
        "outputId": "59060782-78ba-4cba-98a4-22f9f4be9de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entities': [{'label': 'Case',\n",
              "    'id': 'case1',\n",
              "    'summary': 'The patient was a 34-yr-old man who presented with complaints of fever and a chronic cough. He was a smoker and had a history of pulmonary tuberculosis that had been treated and cured. A computed tomographic (CT) scan revealed multiple tiny nodules in both lungs. A thoracoscopic lung biopsy was taken from the right upper lobe. The microscopic examination revealed a typical LCH. The tumor cells had vesicular and grooved nuclei, and they formed small aggregations around the bronchioles. The tumor cells were strongly positive for S-100 protein, vimentin, CD68 and CD1a. There were infiltrations of lymphocytes and eosinophils around the tumor cells. With performing additional radiologic examinations, no other organs were thought to be involved. He quit smoking, but he received no other specific treatment. He was well for the following one year. After this, a follow-up CT scan was performed and it showed a 4 cm-sized mass in the left lower lobe, in addition to the multiple tiny nodules in both lungs. A needle biopsy specimen revealed the possibility of a sarcoma; therefore, a lobectomy was performed. Grossly, a 4 cm-sized poorly-circumscribed lobulated gray-white mass was found , and there were a few small satellite nodules around the main mass. Microscopically, the tumor cells were aggregated in large sheets and they showed an infiltrative growth. The cytologic features of some of the tumor cells were similar to those seen in a typical LCH. However, many tumor cells showed overtly malignant cytologic features such as pleomorphic/hyperchromatic nuclei and prominent nucleoli , and multinucleated tumor giant cells were also found. There were numerous mitotic figures ranging from 30 to 60 per 10 high power fields, and some of them were abnormal. A few foci of typical LCH remained around the main tumor mass. Immunohistochemically, the tumor cells were strongly positive for S-100 protein  and vimentin; they were also positive for CD68 (Dako N1577, Clone KPI), and focally positive for CD1a , and they were negative for cytokeratin, epithelial membrane antigen, CD3, CD20 and HMB45. The ultrastructural analysis failed to demonstrate any Birbeck granules in the cytoplasm of the tumor cells. Now, at five months after lobectomy, the patient is doing well with no significant change in the radiologic findings.'},\n",
              "   {'label': 'Person',\n",
              "    'id': 'person1',\n",
              "    'age': '34',\n",
              "    'location': 'unknown',\n",
              "    'gender': 'male'},\n",
              "   {'label': 'Symptom',\n",
              "    'id': 'fever',\n",
              "    'description': 'patient presented with complaints of fever'},\n",
              "   {'label': 'Symptom',\n",
              "    'id': 'chronicCough',\n",
              "    'description': 'patient presented with complaints of a chronic cough'},\n",
              "   {'label': 'Disease',\n",
              "    'id': 'pulmonaryTuberculosis',\n",
              "    'name': 'Pulmonary Tuberculosis'},\n",
              "   {'label': 'Disease', 'id': 'lch', 'name': 'LCH'},\n",
              "   {'label': 'Disease', 'id': 'sarcoma', 'name': 'Sarcoma'},\n",
              "   {'label': 'BodySystem', 'id': 'lungs', 'name': 'Lungs'},\n",
              "   {'label': 'Diagnosis',\n",
              "    'id': 'ctScan',\n",
              "    'name': 'CT Scan',\n",
              "    'description': 'A computed tomographic (CT) scan revealed multiple tiny nodules in both lungs',\n",
              "    'when': 'unknown'},\n",
              "   {'label': 'Diagnosis',\n",
              "    'id': 'thoracoscopicLungBiopsy',\n",
              "    'name': 'Thoracoscopic Lung Biopsy',\n",
              "    'description': 'A thoracoscopic lung biopsy was taken from the right upper lobe',\n",
              "    'when': 'unknown'},\n",
              "   {'label': 'Diagnosis',\n",
              "    'id': 'needleBiopsy',\n",
              "    'name': 'Needle Biopsy',\n",
              "    'description': 'A needle biopsy specimen revealed the possibility of a sarcoma',\n",
              "    'when': 'unknown'},\n",
              "   {'label': 'Biological',\n",
              "    'id': 'tumorCells',\n",
              "    'name': 'Tumor Cells',\n",
              "    'description': 'The tumor cells had vesicular and grooved nuclei, and they formed small aggregations around the bronchioles'}],\n",
              "  'relationships': ['case1|FOR|person1',\n",
              "   \"person1|HAS_SYMPTOM{when:'unknown',frequency:'unknown',span:'unknown'}|fever\",\n",
              "   \"person1|HAS_SYMPTOM{when:'unknown',frequency:'unknown',span:'unknown'}|chronicCough\",\n",
              "   \"person1|HAS_DISEASE{when:'past'}|pulmonaryTuberculosis\",\n",
              "   \"person1|HAS_DISEASE{when:'present'}|lch\",\n",
              "   \"person1|HAS_DISEASE{when:'present'}|sarcoma\",\n",
              "   'fever|SEEN_ON|lungs',\n",
              "   'chronicCough|SEEN_ON|lungs',\n",
              "   'pulmonaryTuberculosis|AFFECTS|lungs',\n",
              "   'lch|AFFECTS|lungs',\n",
              "   'sarcoma|AFFECTS|lungs',\n",
              "   'person1|HAS_DIAGNOSIS|ctScan',\n",
              "   'person1|HAS_DIAGNOSIS|thoracoscopicLungBiopsy',\n",
              "   'person1|HAS_DIAGNOSIS|needleBiopsy',\n",
              "   'ctScan|SHOWED|tumorCells',\n",
              "   'thoracoscopicLungBiopsy|SHOWED|tumorCells',\n",
              "   'needleBiopsy|SHOWED|tumorCells']}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7b7fe8c3"
      },
      "outputs": [],
      "source": [
        "#pre-processing results for uploading into Neo4j - helper function:\n",
        "def get_prop_str(prop_dict, _id):\n",
        "    s = []\n",
        "    for key, val in prop_dict.items():\n",
        "      if key != 'label' and key != 'id':\n",
        "         s.append(_id+\".\"+key+' = \"'+str(val).replace('\\\"', '\"').replace('\"', '\\\"')+'\"')\n",
        "    return ' ON CREATE SET ' + ','.join(s)\n",
        "\n",
        "def get_cypher_compliant_var(_id):\n",
        "    return \"_\"+ re.sub(r'[\\W_]', '', _id)\n",
        "\n",
        "def generate_cypher(in_json):\n",
        "    e_map = {}\n",
        "    e_stmt = []\n",
        "    r_stmt = []\n",
        "    e_stmt_tpl = Template(\"($id:$label{id:'$key'})\")\n",
        "    r_stmt_tpl = Template(\"\"\"\n",
        "      MATCH $src\n",
        "      MATCH $tgt\n",
        "      MERGE ($src_id)-[:$rel]->($tgt_id)\n",
        "    \"\"\")\n",
        "    for obj in in_json:\n",
        "      for j in obj['entities']:\n",
        "          props = ''\n",
        "          label = j['label']\n",
        "          id = j['id']\n",
        "          if label == 'Case':\n",
        "                id = 'c'+str(time.time_ns())\n",
        "          elif label == 'Person':\n",
        "                id = 'p'+str(time.time_ns())\n",
        "          varname = get_cypher_compliant_var(j['id'])\n",
        "          stmt = e_stmt_tpl.substitute(id=varname, label=label, key=id)\n",
        "          e_map[varname] = stmt\n",
        "          e_stmt.append('MERGE '+ stmt + get_prop_str(j, varname))\n",
        "\n",
        "      for st in obj['relationships']:\n",
        "          rels = st.split(\"|\")\n",
        "          src_id = get_cypher_compliant_var(rels[0].strip())\n",
        "          rel = rels[1].strip()\n",
        "          tgt_id = get_cypher_compliant_var(rels[2].strip())\n",
        "          stmt = r_stmt_tpl.substitute(\n",
        "              src_id=src_id, tgt_id=tgt_id, src=e_map[src_id], tgt=e_map[tgt_id], rel=rel)\n",
        "\n",
        "          r_stmt.append(stmt)\n",
        "\n",
        "    return e_stmt, r_stmt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ent_cyp, rel_cyp = generate_cypher(results)"
      ],
      "metadata": {
        "id": "sEJ0D9tg07Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df1f033e",
        "outputId": "e3654276-e27d-4473-dc6b-bac972920138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 55.4 ms, sys: 9.47 ms, total: 64.9 ms\n",
            "Wall time: 3.72 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for e in ent_cyp:\n",
        "    gds.run_cypher(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "684c1282",
        "outputId": "7ec0d5f3-b4f2-4799-c0e4-813994e1c46d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 87.2 ms, sys: 10.4 ms, total: 97.6 ms\n",
            "Wall time: 7.29 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for r in rel_cyp:\n",
        "    gds.run_cypher(r)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gds.run_cypher(\"\"\"\n",
        "  MATCH (n)\n",
        "  DETACH DELETE n\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "42kVyPJj1UFp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}